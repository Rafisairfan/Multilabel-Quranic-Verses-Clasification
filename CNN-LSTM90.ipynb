{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9266990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic library \n",
    "import pandas as pd                                                       \n",
    "import numpy as np                                                                                                \n",
    "import re                                                                   \n",
    "import joblib           \n",
    "import string                                                                \n",
    "#NLTK Corner \n",
    "import nltk                                                                \n",
    "from nltk.corpus import stopwords                                                                           \n",
    "from nltk.stem import PorterStemmer                                          \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize                                                                                          \n",
    "#Tensorflow Corner \n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection                                                       \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer                     \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences             \n",
    "#Sklearn gang                                                                \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer                   \n",
    "from sklearn.model_selection import train_test_split                          \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer                   \n",
    "#Keras club \n",
    "from keras.models import Sequential                                           \n",
    "from keras import layers                                                     \n",
    "from tensorflow import keras                                                  \n",
    "from keras.preprocessing import sequence                                      \n",
    "from keras.layers import Dense,Flatten, Dropout, Embedding, LSTM, SpatialDropout1D, Conv2D,TimeDistributed, MaxPool1D, Conv1D,GlobalMaxPool1D\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c952e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X.csv')\n",
    "Y = pd.read_csv('Y.csv')\n",
    "Y = Y.drop(\"Unnamed: 0\", axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cb64b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 256\n",
    "MAX_SEQUENCE_LENGTH = 150 \n",
    "EMBEDDING_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a80710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X)\n",
    "word_index = tokenizer.word_index\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35123039",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba543305",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsUgjI2khwv8",
    "outputId": "1dc5c4d0-2911-43d4-e389-b4ed6d195fd2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cf5c9",
   "metadata": {
    "id": "sUDo_f8J4Qq1"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abd30385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Conv1D(filters=512, kernel_size=5, input_shape=(X_train.shape[1],1), activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=5))\n",
    "# model.add(Dropout(0.7))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.BinaryFocalCrossentropy(), optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),metrics=tf.keras.metrics.top_k_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32822d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "176/176 [==============================] - 22s 104ms/step - loss: 0.0222 - top_k_categorical_accuracy: 0.6990 - val_loss: 0.0143 - val_top_k_categorical_accuracy: 0.8958\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 18s 100ms/step - loss: 0.0159 - top_k_categorical_accuracy: 0.7749 - val_loss: 0.0138 - val_top_k_categorical_accuracy: 0.8942\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 18s 100ms/step - loss: 0.0148 - top_k_categorical_accuracy: 0.8243 - val_loss: 0.0134 - val_top_k_categorical_accuracy: 0.8974\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 18s 101ms/step - loss: 0.0141 - top_k_categorical_accuracy: 0.8409 - val_loss: 0.0133 - val_top_k_categorical_accuracy: 0.9054\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0137 - top_k_categorical_accuracy: 0.8526 - val_loss: 0.0131 - val_top_k_categorical_accuracy: 0.9071\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 18s 104ms/step - loss: 0.0133 - top_k_categorical_accuracy: 0.8697 - val_loss: 0.0133 - val_top_k_categorical_accuracy: 0.9071\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 18s 104ms/step - loss: 0.0129 - top_k_categorical_accuracy: 0.8806 - val_loss: 0.0150 - val_top_k_categorical_accuracy: 0.8926\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 17s 98ms/step - loss: 0.0126 - top_k_categorical_accuracy: 0.8829 - val_loss: 0.0161 - val_top_k_categorical_accuracy: 0.8990\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 15s 84ms/step - loss: 0.0120 - top_k_categorical_accuracy: 0.8799 - val_loss: 0.0204 - val_top_k_categorical_accuracy: 0.9006\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 17s 97ms/step - loss: 0.0117 - top_k_categorical_accuracy: 0.8820 - val_loss: 0.0236 - val_top_k_categorical_accuracy: 0.9087\n",
      "20/20 [==============================] - 1s 54ms/step\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0236 - top_k_categorical_accuracy: 0.9087\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 0.0113 - top_k_categorical_accuracy: 0.8781 - val_loss: 0.0290 - val_top_k_categorical_accuracy: 0.8990\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 0.0107 - top_k_categorical_accuracy: 0.8770 - val_loss: 0.0247 - val_top_k_categorical_accuracy: 0.8958\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 23s 131ms/step - loss: 0.0108 - top_k_categorical_accuracy: 0.8856 - val_loss: 0.0249 - val_top_k_categorical_accuracy: 0.8638\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 23s 132ms/step - loss: 0.0109 - top_k_categorical_accuracy: 0.8835 - val_loss: 0.0197 - val_top_k_categorical_accuracy: 0.8894\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 23s 132ms/step - loss: 0.0102 - top_k_categorical_accuracy: 0.8883 - val_loss: 0.0264 - val_top_k_categorical_accuracy: 0.8862\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 23s 131ms/step - loss: 0.0099 - top_k_categorical_accuracy: 0.8926 - val_loss: 0.0415 - val_top_k_categorical_accuracy: 0.8862\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 23s 131ms/step - loss: 0.0095 - top_k_categorical_accuracy: 0.8984 - val_loss: 0.0427 - val_top_k_categorical_accuracy: 0.8622\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 23s 129ms/step - loss: 0.0102 - top_k_categorical_accuracy: 0.8890 - val_loss: 0.0439 - val_top_k_categorical_accuracy: 0.8702\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 21s 118ms/step - loss: 0.0093 - top_k_categorical_accuracy: 0.8877 - val_loss: 0.0435 - val_top_k_categorical_accuracy: 0.8365\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 20s 116ms/step - loss: 0.0092 - top_k_categorical_accuracy: 0.8920 - val_loss: 0.0618 - val_top_k_categorical_accuracy: 0.8686\n",
      "20/20 [==============================] - 1s 48ms/step\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.0618 - top_k_categorical_accuracy: 0.8686\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0090 - top_k_categorical_accuracy: 0.8915 - val_loss: 0.0573 - val_top_k_categorical_accuracy: 0.8638\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 20s 115ms/step - loss: 0.0089 - top_k_categorical_accuracy: 0.8983 - val_loss: 0.0612 - val_top_k_categorical_accuracy: 0.8654\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 0.0087 - top_k_categorical_accuracy: 0.9000 - val_loss: 0.0596 - val_top_k_categorical_accuracy: 0.8173\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 21s 118ms/step - loss: 0.0085 - top_k_categorical_accuracy: 0.8968 - val_loss: 0.0695 - val_top_k_categorical_accuracy: 0.8462\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0082 - top_k_categorical_accuracy: 0.9040 - val_loss: 0.0624 - val_top_k_categorical_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 21s 117ms/step - loss: 0.0081 - top_k_categorical_accuracy: 0.9048 - val_loss: 0.0459 - val_top_k_categorical_accuracy: 0.8157\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 21s 117ms/step - loss: 0.0080 - top_k_categorical_accuracy: 0.8950 - val_loss: 0.0854 - val_top_k_categorical_accuracy: 0.8381\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 20s 115ms/step - loss: 0.0076 - top_k_categorical_accuracy: 0.9050 - val_loss: 0.0847 - val_top_k_categorical_accuracy: 0.8301\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 19s 111ms/step - loss: 0.0075 - top_k_categorical_accuracy: 0.9050 - val_loss: 0.0799 - val_top_k_categorical_accuracy: 0.8157\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 20s 115ms/step - loss: 0.0074 - top_k_categorical_accuracy: 0.9082 - val_loss: 0.0750 - val_top_k_categorical_accuracy: 0.7885\n",
      "20/20 [==============================] - 1s 54ms/step\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0750 - top_k_categorical_accuracy: 0.7885\n",
      "[0.9086538553237915, 0.8685897588729858, 0.7884615659713745]\n",
      "[0.099859774, 0.10076122, 0.1030649]\n"
     ]
    }
   ],
   "source": [
    "acc = []; loss= []\n",
    "for item in range(3) :\n",
    "    epochs = 10\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        batch_size=32,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data = (X_test, Y_test))\n",
    "    item = item + 1\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = (model.evaluate(X_test, Y_test, batch_size=32, verbose=1))\n",
    "    acc.append(score[1])\n",
    "    metric = tfa.metrics.HammingLoss(mode='multilabel', threshold=0.1)\n",
    "    metric.update_state(Y_test, y_pred)\n",
    "    loss.append(metric.result().numpy())\n",
    "\n",
    "    \n",
    "print(acc)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d344e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('clstm_0.098_89.7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09bf3ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10122863203287125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(loss)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94550a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
